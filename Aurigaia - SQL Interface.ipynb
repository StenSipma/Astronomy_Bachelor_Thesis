{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e490665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "from time import process_time\n",
    "from math import pi, radians, degrees\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib.pyplot import figure, subplots, show\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "MAKE_ONLINE_QUERIES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10010c6",
   "metadata": {},
   "source": [
    "Database Names:\n",
    "```\n",
    "H_Au06_L3_Angle030_Ext\n",
    "H_Au16_L3_Angle030_Ext\n",
    "H_Au21_L3_Angle030_Ext\n",
    "H_Au23_L3_Angle030_Ext\n",
    "H_Au24_L3_Angle030_Ext\n",
    "H_Au27_L3_Angle030_Ext\n",
    "\n",
    "I_Au06_L3_Angle030_Ext\n",
    "I_Au16_L3_Angle030_Ext\n",
    "I_Au21_L3_Angle030_Ext\n",
    "I_Au23_L3_Angle030_Ext\n",
    "I_Au24_L3_Angle030_Ext\n",
    "I_Au27_L3_Angle030_Ext\n",
    "\n",
    "I_Au06_L3_Angle030_NoExt\n",
    "I_Au16_L3_Angle030_NoExt\n",
    "I_Au21_L3_Angle030_NoExt\n",
    "I_Au23_L3_Angle030_NoExt\n",
    "I_Au24_L3_Angle030_NoExt\n",
    "I_Au27_L3_Angle030_NoExt \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f585097c",
   "metadata": {},
   "source": [
    "## Request Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9101da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here a more modern interface to VirgoDB\n",
    "import re\n",
    "\n",
    "import h5py\n",
    "import requests\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "VIRGO_DB_BASE_URL = \"http://virgodb.dur.ac.uk:8080/MyMillennium\"\n",
    "\n",
    "CHUNK_SIZE = 8192\n",
    "LINE_CHUNK_SIZE = 1048\n",
    "\n",
    "# Mapping between SQL and numpy types\n",
    "numpy_dtype = {\n",
    "    \"real\": np.float32,\n",
    "    \"float\": np.float64,\n",
    "    \"int\": np.int32,\n",
    "    \"bigint\": np.int64,\n",
    "    \"char\": np.dtype(\"|S256\"),\n",
    "    \"nvarchar\": np.dtype(\"|S256\"),\n",
    "    \"decimal\": np.float64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VirgoDBError(Exception):\n",
    "    \"\"\"Base class for exceptions raised by this module\"\"\"\n",
    "    pass\n",
    "\n",
    "class SQLError(VirgoDBError):\n",
    "    \"\"\"Exception raised if an SQL query fails\"\"\"\n",
    "    pass\n",
    "\n",
    "class BadResponseError(VirgoDBError):\n",
    "    \"\"\"Exception raised if we can't interpret the result of a query\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d503baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import dropwhile\n",
    "\n",
    "\n",
    "def read_column_info(lines_gen):\n",
    "    \"\"\"\n",
    "    Parse the first few lines of the returned CSV file. All the 'metadata' is\n",
    "    prefixed with a #. The generator consumes all the # lines and the first line\n",
    "    with no # sign (should be the comma separated names again)\n",
    "    \"\"\"\n",
    "    # Skip rows until we reach QUERYTIMEOUT\n",
    "    lines_gen = dropwhile(lambda l: not l.startswith(\"#QUERYTIMEOUT\"), lines_gen)\n",
    "\n",
    "    # Skip QUERYTIMEOUT & QUERYTIME\n",
    "    if not(next(lines_gen).startswith(\"#QUERYTIMEOUT\")):\n",
    "        raise BadResponseError(\"Don't understand result header!\")\n",
    "        \n",
    "    if not(next(lines_gen).startswith(\"#QUERYTIME\")):\n",
    "        raise BadResponseError(\"Don't understand result header!\")\n",
    "\n",
    "    # Read column info\n",
    "    # (also discards line with full list of column names)\n",
    "    columns = []\n",
    "    while True:\n",
    "        line = next(lines_gen)\n",
    "        if line[0] != \"#\":\n",
    "            break\n",
    "        else:\n",
    "            m = re.match(\"^#COLUMN ([0-9]+) name=([\\w]+) JDBC_TYPE=(-?[0-9]+) JDBC_TYPENAME=([\\w]+)$\", line)\n",
    "            if m is not None:\n",
    "                columns.append(m.groups())\n",
    "            else:\n",
    "                raise BadResponseError(\"Don't understand column info: \"+line)\n",
    "\n",
    "    # Turn parsed column info into meaningful quantities\n",
    "    names = [col[1] for col in columns]\n",
    "    dtypes = [numpy_dtype[col[3]] for col in columns]\n",
    "    rectype = np.dtype([(col[1], numpy_dtype[col[3]]) for col in columns])\n",
    "    return names, dtypes, rectype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f82cf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_query_hdf5(query: str, filename: str, conn: requests.Session, force=False, verbose=False):\n",
    "    \"\"\"\n",
    "    Makes a query to the Millenium database and streams it to a new HDF5 file.\n",
    "    Code is adapted from the VirgoDB client:\n",
    "        http://virgodb.dur.ac.uk:8080/MyMillennium/pages/help/python/virgodb.py\n",
    "    \"\"\"\n",
    "\n",
    "    if not MAKE_ONLINE_QUERIES and not force:\n",
    "        print(\"Making queries disabled\")\n",
    "        return filename, None\n",
    "    \n",
    "    payload = {\n",
    "        'action': 'doQuery',\n",
    "        'SQL': query,\n",
    "    }\n",
    "    \n",
    "    start = process_time()\n",
    "    \n",
    "    with conn.get(VIRGO_DB_BASE_URL, params=payload, stream=True) as r:\n",
    "        # Throw exception if there is some error\n",
    "        r.raise_for_status()\n",
    "\n",
    "        lines = r.iter_lines(chunk_size=CHUNK_SIZE, decode_unicode=True)\n",
    "\n",
    "        # Read column info\n",
    "        names, dtypes, rectype = read_column_info(lines)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Column info:\")\n",
    "            for i, (n, d) in enumerate(zip(names, dtypes)):\n",
    "                print(f\"{n}  {d}  {rectype[i]}\")\n",
    "        # Create the output file and datasets\n",
    "        with h5py.File(filename, \"w\") as out:\n",
    "            for name, dtype in zip(names, dtypes):\n",
    "                out.create_dataset(name,\n",
    "                                   dtype=dtype,\n",
    "                                   shape=(0, ),\n",
    "                                   maxshape=(None, ),\n",
    "                                   chunks=(LINE_CHUNK_SIZE, ))\n",
    "\n",
    "            # Iterate over the remaining lines & put them in the hdf5 file\n",
    "            read_lines = \"\\n\".join(l for _, l in zip(range(LINE_CHUNK_SIZE), lines))\n",
    "            nwritten = 0\n",
    "            while read_lines != \"\":\n",
    "\n",
    "                # Turn the read lines into a list of tuples for the data\n",
    "                f = StringIO(read_lines)\n",
    "                dtypes = {name: rectype.fields[name][0] for name in rectype.names}\n",
    "                data = pd.read_csv(f,\n",
    "                                   names=rectype.names,\n",
    "                                   dtype=dtypes,\n",
    "                                   delimiter=\",\",\n",
    "                                   engine=\"c\").to_records(index=False)\n",
    "\n",
    "                # Insert into the HDF5 file\n",
    "                for name in names:\n",
    "                    dataset = out[name]\n",
    "                    dataset.resize((nwritten+data.shape[0],))\n",
    "                    dataset[nwritten:nwritten+data.shape[0]] = data[name]\n",
    "\n",
    "                nwritten += data.shape[0]\n",
    "\n",
    "                read_lines = \"\\n\".join(l for _, l in zip(range(LINE_CHUNK_SIZE), lines))\n",
    "\n",
    "    end = process_time()\n",
    "    duration = end - start\n",
    "    print(f\"Query download took {duration:.4f}s\")\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c330a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_query(query: str, filename: str, conn: requests.Session, force=False):\n",
    "    # Inspiration taken from SO answer:\n",
    "    # https://stackoverflow.com/questions/16694907/download-large-file-in-python-with-requests\n",
    "\n",
    "    if not MAKE_ONLINE_QUERIES and not force:\n",
    "        print(\"Making queries disabled\")\n",
    "        return filename, None\n",
    "\n",
    "    payload = {\n",
    "        'action': 'doQuery',\n",
    "        'SQL': query,\n",
    "    }\n",
    "    # TODO: Assert that the file exists and is empty\n",
    "\n",
    "    # Make query\n",
    "    headers = None\n",
    "    start = process_time()\n",
    "    \n",
    "    with conn.get(VIRGO_DB_BASE_URL, params=payload, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        headers = r.headers\n",
    "        with open(filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=CHUNK_SIZE):\n",
    "                f.write(chunk)\n",
    "                \n",
    "    end = process_time()\n",
    "    duration = end - start\n",
    "    print(f\"Query download took {duration:.4f}s\")\n",
    "    \n",
    "    return filename, headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7afa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "conn = requests.Session()\n",
    "\n",
    "# TODO: move to file or input\n",
    "username = \"USERNAME\"\n",
    "password = \"PASSWORD\"\n",
    "conn.auth = (username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40dc30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vaex\n",
    "\n",
    "query = \"\"\"\n",
    "select top 10000 RA, Dec, ParticleId\n",
    "from  Grand2018a..H_Au06_L3_Angle030_Ext \n",
    "\"\"\"\n",
    "\n",
    "outfile = \"tmp.hdf5\"\n",
    "stream_query_hdf5(query, outfile, conn, force=True)\n",
    "\n",
    "df = vaex.open(outfile)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c68ab21",
   "metadata": {},
   "source": [
    "## Coordinate stuffs\n",
    "\\begin{align*}\n",
    "\\sin b &= sin\\delta_{NGP}\\sin\\delta + cos\\delta_{NGP}\\cos(\\alpha - \\alpha_{NGP})\\\\\n",
    "\\cos b \\sin(l_{NCP} - l) &= \\cos\\delta\\sin(\\alpha- \\alpha_{NGP})\\\\\n",
    "\\cos b \\cos(l_{NCP} - l) &= \\cos\\delta_{NGP}\\sin\\delta - \\sin\\delta_{NGP}\\cos\\delta\\cos(\\alpha- \\alpha_{NGP})\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83941ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_pandas_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5639a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard coordinates\n",
    "NGP = SkyCoord(0, 90, unit=u.deg, frame='galactic').icrs\n",
    "RA_NGP = NGP.ra.to(u.rad).value\n",
    "DEC_NGP = NGP.dec.to(u.rad).value\n",
    "\n",
    "NCP = SkyCoord(0, 90, unit=u.deg, frame='icrs').galactic\n",
    "l_NCP = NCP.l.to(u.rad).value\n",
    "\n",
    "\n",
    "# Some sample coordinates\n",
    "RA = df['RA'][:10]\n",
    "Dec = df['Dec'][:10]\n",
    "\n",
    "\n",
    "# WORKS: \n",
    "b = np.arcsin(np.sin(DEC_NGP)*np.sin(Dec) + np.cos(DEC_NGP)*np.cos(Dec)*np.cos(RA - RA_NGP))\n",
    "b_str = f\"asin(sin({DEC_NGP})*sin(Dec) + cos({DEC_NGP})*cos(Dec)*cos(RA - {RA_NGP})) as b\"\n",
    "\n",
    "# Seems to work:\n",
    "l = l_NCP - np.arctan2( np.cos(Dec)*np.sin(RA - RA_NGP) ,\n",
    "                       np.cos(DEC_NGP)*np.sin(Dec) - np.sin(DEC_NGP)*np.cos(Dec)*np.cos(RA - RA_NGP) )\n",
    "l_str = f\"{l_NCP} - atn2(cos(Dec)*sin(RA - {RA_NGP}) , cos({DEC_NGP})*sin(Dec) - sin({DEC_NGP})*cos(Dec)*cos(RA - {RA_NGP}) ) as l\"\n",
    "\n",
    "print('-----------')\n",
    "\n",
    "c = SkyCoord(RA, Dec, unit=u.rad, frame='icrs').galactic\n",
    "ref_b = c.b.to(u.rad).value\n",
    "print(ref_b - b)\n",
    "\n",
    "print('-----------')\n",
    "\n",
    "ref_l = c.l.to(u.rad).value\n",
    "print(ref_l - l)\n",
    "\n",
    "print('-----------')\n",
    "print(b_str)\n",
    "print()\n",
    "print(l_str)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a57c6",
   "metadata": {},
   "source": [
    "## Box Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac2156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_query = \"\"\"\n",
    "SELECT *    \n",
    "    FROM (\n",
    "        SELECT *, \n",
    "        CASE WHEN l_ > PI() THEN l_ - 2*PI() ELSE l_ END as l,\n",
    "        CASE WHEN b_ > PI() THEN b_ - 2*PI() ELSE b_ END as b\n",
    "        FROM (\n",
    "            SELECT\n",
    "                *,\n",
    "                asin(sin(0.4734773249532946)*sin(Dec) + cos(0.4734773249532946)*cos(Dec)*cos(RA - 3.366032882941064)) as b_,\n",
    "                2.145566851522591 - atn2( cos(Dec)*sin(RA - 3.366032882941064) , cos(0.4734773249532946)*sin(Dec) - sin(0.4734773249532946)*cos(Dec)*cos(RA - 3.366032882941064) ) as l_\n",
    "            FROM  {table_name}\n",
    "            WHERE     \n",
    "                    ((Gmagnitude between 13.5 and 16.5) OR (GmagnitudeObs between 13.5 and 16.5))\n",
    "                AND ((parallax - parallaxerror < 0.00025) OR (parallaxobs - parallaxerror < 0.00025))\n",
    "\n",
    "            ) as tbl1\n",
    "        ) as tbl2\n",
    "\n",
    "WHERE \n",
    "    l between {lower} and {upper} AND\n",
    "    b between {lower} and {upper}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88545e43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lim = radians(12)\n",
    "query = general_query.format(table_name='Grand2018a..H_Au06_L3_Angle030_Ext', lower=-lim, upper=lim)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e6c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_query = general_query.format(table_name='Grand2018a..H_Au06_L3_Angle030_Ext', lower=-lim, upper=lim)\n",
    "box_file = './data/H_Au06_Ext.hdf5'\n",
    "stream_query_hdf5(box_query, box_file, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f635e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_file = './data/I_Au06_Ext.hdf5'\n",
    "box_query = general_query.format(table_name='Grand2018a..I_Au06_L3_Angle030_Ext', lower=-lim, upper=lim)\n",
    "stream_query_hdf5(box_query, box_file, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d438d41",
   "metadata": {},
   "source": [
    "**NOTE: this times out after some time. Not sure why, because the query should be larger if possible.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e2a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_file = './data/I_Au06_NoExt.csv'\n",
    "box_file_hdf5 = './data/I_Au06_NoExt.hdf5'\n",
    "box_query = general_query.format(table_name='Grand2018a..I_Au06_L3_Angle030_NoExt', lower=-lim, upper=lim)\n",
    "stream_query(box_query, box_file, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77911a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old reading from the CSV file. Do this once, and convert it to a HDF5\n",
    "box_file_hdf5 = './data/I_Au06_NoExt.hdf5'\n",
    "df = vaex.from_csv(box_file, convert=box_file_hdf5, comment='#')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb51651",
   "metadata": {},
   "source": [
    "Idea, make a list of all the stars is the selection and query their IDs. This should result in a lot less stars in the query.\n",
    "\n",
    "```python\n",
    "in_query = \"\"\"\n",
    "SELECT * FROM Grand2018a..I_Au06_L3_Angle030_NoExt\n",
    "WHERE StarID in (\n",
    "    {}\n",
    ")\n",
    "\"\"\".format()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e24da",
   "metadata": {},
   "source": [
    "## Determine the limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "pointings_fn = './data/fieldcenters_spec.csv'\n",
    "select = 2  # control the number of pointings\n",
    "\n",
    "def read_pointings(filename):\n",
    "    ls = []\n",
    "    bs = []\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = list(csv.reader(f))\n",
    "        for line in reader[1:]:\n",
    "            l, b = line\n",
    "            ls.append(float(l.strip()))\n",
    "            bs.append(float(b.strip()))\n",
    "\n",
    "    ls = np.array(ls)\n",
    "    bs = np.array(bs)\n",
    "    return ls, bs\n",
    "\n",
    "ls, bs = read_pointings(pointings_fn)\n",
    "ls = np.where(ls > 180, ls - 360, ls)\n",
    "bs = np.where(bs > 180, bs - 360, bs)\n",
    "print(ls)\n",
    "print(bs)\n",
    "\n",
    "pointings = SkyCoord(ls, bs, unit=u.deg, frame='galactic')\n",
    "pointings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95035f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = min(ls.min(), bs.min()) - 1\n",
    "print(lower)\n",
    "\n",
    "upper = max(ls.max(), bs.max()) - 1\n",
    "print(upper)\n",
    "\n",
    "print(ls.min(), ls.max())\n",
    "print(bs.min(), bs.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19c345",
   "metadata": {},
   "source": [
    "Conclusion: Easiest is just to query the 12x12 area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe453924",
   "metadata": {},
   "source": [
    "count: 207293135 (parallax - parallaxerror) > 0.00025)\n",
    "count: 597414673 (parallax - parallaxerror < 0.00025)\n",
    "count: 150032778 parallaxobs < 0!!!!\n",
    "count: 654675042 parallaxobs > 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3 - 2021.11",
   "language": "python",
   "name": "python3-2021.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
